#' @param <%= name %>
#'   The activation function to apply to each layer. This can either be an
#'   actual activation function (e.g. \code{tf$nn$relu}), or the name of an
#'   activation function (e.g. \code{"relu"}). Defaults to the
#'   \code{"<%= default %>"} activation function. See
#'   \url{https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn}
#'   for documentation related to the set of activation functions available
#'   in TensorFlow.
